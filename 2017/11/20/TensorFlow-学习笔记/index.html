


<!DOCTYPE html>
<html lang="zh-cn">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  <meta name="viewport" content="initial-scale=1, width=device-width">
  <title>TensorFlow 学习笔记 [ 不会跳舞的鸟 ]</title>
  
    <!-- stylesheets list from _config.yml -->
    
      <link rel="stylesheet" href="/css/acanal.css">
    
      <link rel="stylesheet" href="/css/responsive.css">
    
      <link rel="stylesheet" href="/css/highlight.css">
    
  
  <script src="//instant.page/5.1.0" type="module" integrity="sha384-by67kQnR+pyfy8yWP4kPO12fHKRLHZPfEsiSXR8u2IKcTdxD805MGUXBzVPnkLHw"></script>
</head>
<body>


  <aside id="post-toc" role="navigator">
    <div id="post-toc-inner">
        <strong class="post-toc-title">Catalog</strong>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#TensorFlow-学习笔记"><span class="toc-number">1.</span> <span class="toc-text">TensorFlow 学习笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#定义公式"><span class="toc-number">1.1.</span> <span class="toc-text">定义公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#流程"><span class="toc-number">1.2.</span> <span class="toc-text">流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-relu"><span class="toc-number">1.3.</span> <span class="toc-text">tf.nn.relu</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-tanh"><span class="toc-number">1.4.</span> <span class="toc-text">tf.nn.tanh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-moment"><span class="toc-number">1.5.</span> <span class="toc-text">tf.nn.moment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-softmax-cross-entropy-with-logits"><span class="toc-number">1.6.</span> <span class="toc-text">tf.nn.softmax_cross_entropy_with_logits()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-stack"><span class="toc-number">1.7.</span> <span class="toc-text">tf.stack()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-dropout"><span class="toc-number">1.8.</span> <span class="toc-text">tf.nn.dropout()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-truncated-normal"><span class="toc-number">1.9.</span> <span class="toc-text">tf.truncated_normal()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-reshape"><span class="toc-number">1.10.</span> <span class="toc-text">tf.reshape()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-reduce-mean"><span class="toc-number">1.11.</span> <span class="toc-text">tf.reduce_mean()</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Others"><span class="toc-number">2.</span> <span class="toc-text">Others</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-name-scope"><span class="toc-number">2.1.</span> <span class="toc-text">tf.name_scope()</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scope-reuse-variables"><span class="toc-number">2.1.1.</span> <span class="toc-text">scope.reuse_variables()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-equal"><span class="toc-number">2.2.</span> <span class="toc-text">tf.equal()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-cast"><span class="toc-number">2.3.</span> <span class="toc-text">tf.cast()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-placeholder"><span class="toc-number">2.4.</span> <span class="toc-text">tf.placeholder()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-argmax"><span class="toc-number">2.5.</span> <span class="toc-text">tf.argmax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-train"><span class="toc-number">2.6.</span> <span class="toc-text">tf.train</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-train-Saver"><span class="toc-number">2.6.1.</span> <span class="toc-text">tf.train.Saver()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-nn-rnn-cell"><span class="toc-number">2.7.</span> <span class="toc-text">tf.nn.rnn_cell</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-train-GradientDescentOptimizer"><span class="toc-number">2.7.1.</span> <span class="toc-text">tf.train.GradientDescentOptimizer()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-summary-FileWriter"><span class="toc-number">2.8.</span> <span class="toc-text">tf.summary.FileWriter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-global-variables-initializer"><span class="toc-number">2.9.</span> <span class="toc-text">tf.global_variables_initializer()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-matmul"><span class="toc-number">2.10.</span> <span class="toc-text">tf.matmul()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tf-square"><span class="toc-number">2.11.</span> <span class="toc-text">tf.square()</span></a></li></ol></li></ol>
    </div>  
</aside>



<div id="main">
  <div id="menu-outer">
    <div id="menu-inner">
      
        <a href="/">Home</a>
      
        <a href="/about">About</a>
      
        <a href="/links">Links</a>
      
        <a href="/archives">Archives</a>
      
        <a href="/ffmpeg-cmd-viewer">FCV</a>
      
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      

<article id="post">
  <header class="page-header">
  <div id="site-info">
    <div class="post-date-left">
      
        Create: Mon Nov 20 2017 00:17:16 GMT+0800
      
    </div>
    <div class="site-title-area">
      <div class="site-title">不会跳舞的鸟</div>
      <div class="site-subtitle">学习笔记、日记</div>
    </div>
    <div class="post-date-right">
      
        Update: Fri Jul 08 2022 19:50:27 GMT+0800
      
    </div>
  </div>
</header>
  
  <h1>TensorFlow 学习笔记</h1>
  <div class="post-body">
    <h1 id="TensorFlow-学习笔记"><a href="#TensorFlow-学习笔记" class="headerlink" title="TensorFlow 学习笔记"></a>TensorFlow 学习笔记</h1><p>@(深度学习)</p>
<p>纯粹的学习笔记，写给自己看的，防止遗忘。</p>
<h2 id="定义公式"><a href="#定义公式" class="headerlink" title="定义公式"></a>定义公式</h2><p>定义的公式只是 Computation Graph，在这执行这代码时计算还没发生，需要调用 run 方法并 feed 数据才真正执行。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol>
<li>定义算法公式，也就是神经网络 forward 时的计算。</li>
<li>定义 loss ，选定优化器，并指定优化器优化 loss。</li>
<li>迭代地对数据进行训练。</li>
<li>在测试集或验证集上对准确率进行评测。</li>
</ol>
<p>lambda</p>
<p>dense</p>
<h2 id="tf-nn-relu"><a href="#tf-nn-relu" class="headerlink" title="tf.nn.relu"></a>tf.nn.relu</h2><h2 id="tf-nn-tanh"><a href="#tf-nn-tanh" class="headerlink" title="tf.nn.tanh"></a>tf.nn.tanh</h2><h2 id="tf-nn-moment"><a href="#tf-nn-moment" class="headerlink" title="tf.nn.moment"></a>tf.nn.moment</h2><h2 id="tf-nn-softmax-cross-entropy-with-logits"><a href="#tf-nn-softmax-cross-entropy-with-logits" class="headerlink" title="tf.nn.softmax_cross_entropy_with_logits()"></a>tf.nn.softmax_cross_entropy_with_logits()</h2><p>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))<br>    =&gt;<br>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))</p>
<h2 id="tf-stack"><a href="#tf-stack" class="headerlink" title="tf.stack()"></a>tf.stack()</h2><p>tf.pack() =&gt; tf.stack()<br>tf.unpack() =&gt; tf.unstack()</p>
<h2 id="tf-nn-dropout"><a href="#tf-nn-dropout" class="headerlink" title="tf.nn.dropout()"></a>tf.nn.dropout()</h2><h2 id="tf-truncated-normal"><a href="#tf-truncated-normal" class="headerlink" title="tf.truncated_normal()"></a>tf.truncated_normal()</h2><h2 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a>tf.reshape()</h2><p>重新变换形状</p>
<h2 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean()"></a>tf.reduce_mean()</h2><p>在某一维度上求平均值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reduce_mean(</span><br><span class="line">    input_tensor,</span><br><span class="line">    axis=None,</span><br><span class="line">    keepdims=None,</span><br><span class="line">    name=None,</span><br><span class="line">    reduction_indices=None,</span><br><span class="line">    keep_dims=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable()</span><br></pre></td></tr></table></figure>
<h2 id="tf-name-scope"><a href="#tf-name-scope" class="headerlink" title="tf.name_scope()"></a>tf.name_scope()</h2><p>对 tf.get_variable() 无效</p>
<h3 id="scope-reuse-variables"><a href="#scope-reuse-variables" class="headerlink" title="scope.reuse_variables()"></a>scope.reuse_variables()</h3><p>后面加    tf.get_variable() 可以重复用</p>
<h2 id="tf-equal"><a href="#tf-equal" class="headerlink" title="tf.equal()"></a>tf.equal()</h2><p>判断两个是否相等</p>
<h2 id="tf-cast"><a href="#tf-cast" class="headerlink" title="tf.cast()"></a>tf.cast()</h2><p>映射，参数一映射为参数二的类型</p>
<h2 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder()"></a>tf.placeholder()</h2><p>占位符<br>input = tf.placeholder(tf.float32)<br>操作 = 函数(input)<br>sess.run(操作, feed_dict = {input: 2})</p>
<p>tf.placeholder(tf.float32, [None, 784])<br>第二个参数代表 tensor 的 shape， 也就是数据的尺寸。<br>None 代表不限条数的输入，784 代表每条输入是一个784 维的向量。</p>
<h2 id="tf-argmax"><a href="#tf-argmax" class="headerlink" title="tf.argmax"></a>tf.argmax</h2><p>返回最大值的索引</p>
<h2 id="tf-train"><a href="#tf-train" class="headerlink" title="tf.train"></a>tf.train</h2><h3 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver()"></a>tf.train.Saver()</h3><p>保存(save) 恢复(restore) 模型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># save</span><br><span class="line">saver.save(sess, &apos;my-model&apos;, global_step = 0)</span><br><span class="line"># restore</span><br><span class="line">saver.restore(sess, &apos;my-model&apos;)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-nn-rnn-cell"><a href="#tf-nn-rnn-cell" class="headerlink" title="tf.nn.rnn_cell"></a>tf.nn.rnn_cell</h2><p>tf.nn.rnn_cell =&gt; tf.contrib.rnn</p>
<h3 id="tf-train-GradientDescentOptimizer"><a href="#tf-train-GradientDescentOptimizer" class="headerlink" title="tf.train.GradientDescentOptimizer()"></a>tf.train.GradientDescentOptimizer()</h3><p>梯度下降优化器</p>
<h2 id="tf-summary-FileWriter"><a href="#tf-summary-FileWriter" class="headerlink" title="tf.summary.FileWriter"></a>tf.summary.FileWriter</h2><p>tf.trian.SummaryWriter =&gt; tf.summary.FileWriter<br>Writes Summary protocol buffers to event files.</p>
<h2 id="tf-global-variables-initializer"><a href="#tf-global-variables-initializer" class="headerlink" title="tf.global_variables_initializer()"></a>tf.global_variables_initializer()</h2><p>tf.initialize_all_variables() =&gt; tf.global_variables_initializer()</p>
<h2 id="tf-matmul"><a href="#tf-matmul" class="headerlink" title="tf.matmul()"></a>tf.matmul()</h2><p>两个矩阵相乘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">matmul(</span><br><span class="line">    a,</span><br><span class="line">    b,</span><br><span class="line">    transpose_a=False,</span><br><span class="line">    transpose_b=False,</span><br><span class="line">    adjoint_a=False,</span><br><span class="line">    adjoint_b=False,</span><br><span class="line">    a_is_sparse=False,</span><br><span class="line">    b_is_sparse=False,</span><br><span class="line">    name=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="tf-square"><a href="#tf-square" class="headerlink" title="tf.square()"></a>tf.square()</h2><p>平方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">square(</span><br><span class="line">    x,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
  </div>
</article>

<div id="paginator">
  
</div>

    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      <div id="footer-info">
        <div class="post-date-left">
          
            Create: Mon Nov 20 2017 00:17:16 GMT+0800
          
        </div>
        <div class="site-title-area">
          <div class="site-title">
            
              我们生来就是孤独，我们生来就是孤单。
            
          </div>
          <div class="site-subtitle">
            Site by Shangxin using
            <a href="http://hexo.io">hexo blog framework</a>
          </div>
        </div>
        <div class="post-date-right">
          
            Update: Fri Jul 08 2022 19:50:27 GMT+0800
          
        </div>
      </div>
      
        

    <div class="vcomments" id="vcomments"></div>
    <script src="https://lib.baomitu.com/valine/latest/Valine.min.js"></script>
    <script>
        new Valine({
            el: '#vcomments',
            appId: 'b47PMHdzebB0ozGGdW68aQAN-gzGzoHsz',
            appKey: 'pnCuygqUh5uDjQt8wNEKSd8K',
            notify: 'false',
            verify: 'false',
            avatar: 'mp',
            pageSize: '10',
            placeholder: '请输入...',
            visitor: 'true'
        })
    </script>

        
          <span id="/2017/11/20/TensorFlow-学习笔记/" class="leancloud-visitors view" data-flag-title>
            <em class="post-meta-item-text">阅读量 </em>
            <i class="leancloud-visitors-count">不知道 &gt;_&lt;</i>
          </span>
        
      
      <!-- 不蒜子网站访问量统计 -->
      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
      <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    </div>
  </div>
</div>

  <!-- scripts list from theme config.yml -->
  
    <script src="/js/acanal.js"></script>
  


</body>
</html>
