


<!DOCTYPE html>
<html lang="zh-cn">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  <title>TensorFlow 学习笔记 [ 不懂鸟语的人 ]</title>
  
    <!-- stylesheets list from _config.yml -->
    
      <link rel="stylesheet" href="/css/acanal.css">
    
      <link rel="stylesheet" href="/css/highlight.css">
    
  
</head>
<body>

<div id="menu-outer">
  <div id="menu-inner">
    
      <a href="/">Home</a>
    
      <a href="/about">About</a>
    
      <a href="/links">Links</a>
    
      <a href="/archives">Archives</a>
    
  </div>
</div>

<div id="content-outer">
  <div id="content-inner">
    
<article id="post">
  <header class="page-header">
  <div id="site-info">
    <div class="post-date-left">
      
        Mon Nov 20 2017 00:17:16 GMT+0800
      
    </div>
    <div class="site-title-area">
      <div class="site-title">不懂鸟语的人</div>
      <div class="site-subtitle">我的个人学习笔记</div>
    </div>
    <div class="post-date-right">
      
        Mon Nov 20 2017 00:17:16 GMT+0800
      
    </div>
  </div>
</header>
  
  <h1>TensorFlow 学习笔记</h1>
  <div class="post-body">
    <h1 id="TensorFlow-学习笔记"><a href="#TensorFlow-学习笔记" class="headerlink" title="TensorFlow 学习笔记"></a>TensorFlow 学习笔记</h1><p>@(深度学习)</p>
<p>纯粹的学习笔记，写给自己看的，防止遗忘。</p>
<h2 id="定义公式"><a href="#定义公式" class="headerlink" title="定义公式"></a>定义公式</h2><p>定义的公式只是 Computation Graph，在这执行这代码时计算还没发生，需要调用 run 方法并 feed 数据才真正执行。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol>
<li>定义算法公式，也就是神经网络 forward 时的计算。</li>
<li>定义 loss ，选定优化器，并指定优化器优化 loss。</li>
<li>迭代地对数据进行训练。</li>
<li>在测试集或验证集上对准确率进行评测。</li>
</ol>
<p>lambda</p>
<p>dense</p>
<h2 id="tf-nn-relu"><a href="#tf-nn-relu" class="headerlink" title="tf.nn.relu"></a>tf.nn.relu</h2><h2 id="tf-nn-tanh"><a href="#tf-nn-tanh" class="headerlink" title="tf.nn.tanh"></a>tf.nn.tanh</h2><h2 id="tf-nn-moment"><a href="#tf-nn-moment" class="headerlink" title="tf.nn.moment"></a>tf.nn.moment</h2><h2 id="tf-nn-softmax-cross-entropy-with-logits"><a href="#tf-nn-softmax-cross-entropy-with-logits" class="headerlink" title="tf.nn.softmax_cross_entropy_with_logits()"></a>tf.nn.softmax_cross_entropy_with_logits()</h2><p>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))<br>    =&gt;<br>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))</p>
<h2 id="tf-stack"><a href="#tf-stack" class="headerlink" title="tf.stack()"></a>tf.stack()</h2><p>tf.pack() =&gt; tf.stack()<br>tf.unpack() =&gt; tf.unstack()</p>
<h2 id="tf-nn-dropout"><a href="#tf-nn-dropout" class="headerlink" title="tf.nn.dropout()"></a>tf.nn.dropout()</h2><h2 id="tf-truncated-normal"><a href="#tf-truncated-normal" class="headerlink" title="tf.truncated_normal()"></a>tf.truncated_normal()</h2><h2 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a>tf.reshape()</h2><p>重新变换形状</p>
<h2 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean()"></a>tf.reduce_mean()</h2><p>在某一维度上求平均值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reduce_mean(</span><br><span class="line">    input_tensor,</span><br><span class="line">    axis=None,</span><br><span class="line">    keepdims=None,</span><br><span class="line">    name=None,</span><br><span class="line">    reduction_indices=None,</span><br><span class="line">    keep_dims=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable()</span><br></pre></td></tr></table></figure>
<h2 id="tf-name-scope"><a href="#tf-name-scope" class="headerlink" title="tf.name_scope()"></a>tf.name_scope()</h2><p>对 tf.get_variable() 无效</p>
<h3 id="scope-reuse-variables"><a href="#scope-reuse-variables" class="headerlink" title="scope.reuse_variables()"></a>scope.reuse_variables()</h3><p>后面加    tf.get_variable() 可以重复用</p>
<h2 id="tf-equal"><a href="#tf-equal" class="headerlink" title="tf.equal()"></a>tf.equal()</h2><p>判断两个是否相等</p>
<h2 id="tf-cast"><a href="#tf-cast" class="headerlink" title="tf.cast()"></a>tf.cast()</h2><p>映射，参数一映射为参数二的类型</p>
<h2 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder()"></a>tf.placeholder()</h2><p>占位符<br>input = tf.placeholder(tf.float32)<br>操作 = 函数(input)<br>sess.run(操作, feed_dict = {input: 2})</p>
<p>tf.placeholder(tf.float32, [None, 784])<br>第二个参数代表 tensor 的 shape， 也就是数据的尺寸。<br>None 代表不限条数的输入，784 代表每条输入是一个784 维的向量。</p>
<h2 id="tf-argmax"><a href="#tf-argmax" class="headerlink" title="tf.argmax"></a>tf.argmax</h2><p>返回最大值的索引</p>
<h2 id="tf-train"><a href="#tf-train" class="headerlink" title="tf.train"></a>tf.train</h2><h3 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver()"></a>tf.train.Saver()</h3><p>保存(save) 恢复(restore) 模型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># save</span><br><span class="line">saver.save(sess, &apos;my-model&apos;, global_step = 0)</span><br><span class="line"># restore</span><br><span class="line">saver.restore(sess, &apos;my-model&apos;)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-nn-rnn-cell"><a href="#tf-nn-rnn-cell" class="headerlink" title="tf.nn.rnn_cell"></a>tf.nn.rnn_cell</h2><p>tf.nn.rnn_cell =&gt; tf.contrib.rnn</p>
<h3 id="tf-train-GradientDescentOptimizer"><a href="#tf-train-GradientDescentOptimizer" class="headerlink" title="tf.train.GradientDescentOptimizer()"></a>tf.train.GradientDescentOptimizer()</h3><p>梯度下降优化器</p>
<h2 id="tf-summary-FileWriter"><a href="#tf-summary-FileWriter" class="headerlink" title="tf.summary.FileWriter"></a>tf.summary.FileWriter</h2><p>tf.trian.SummaryWriter =&gt; tf.summary.FileWriter<br>Writes Summary protocol buffers to event files.</p>
<h2 id="tf-global-variables-initializer"><a href="#tf-global-variables-initializer" class="headerlink" title="tf.global_variables_initializer()"></a>tf.global_variables_initializer()</h2><p>tf.initialize_all_variables() =&gt; tf.global_variables_initializer()</p>
<h2 id="tf-matmul"><a href="#tf-matmul" class="headerlink" title="tf.matmul()"></a>tf.matmul()</h2><p>两个矩阵相乘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">matmul(</span><br><span class="line">    a,</span><br><span class="line">    b,</span><br><span class="line">    transpose_a=False,</span><br><span class="line">    transpose_b=False,</span><br><span class="line">    adjoint_a=False,</span><br><span class="line">    adjoint_b=False,</span><br><span class="line">    a_is_sparse=False,</span><br><span class="line">    b_is_sparse=False,</span><br><span class="line">    name=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="tf-square"><a href="#tf-square" class="headerlink" title="tf.square()"></a>tf.square()</h2><p>平方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">square(</span><br><span class="line">    x,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
  </div>
</article>

<div id="paginator">
  
</div>

  </div>
</div>

<div id="bottom-outer">
  <div id="bottom-inner">
    <div id="footer-info">
      <div class="post-date-left">
        
          Mon Nov 20 2017 00:17:16 GMT+0800
        
      </div>
      <div class="site-title-area">
        <div class="site-title">
          <a href="/">Home</a>
        </div>
        <div class="site-subtitle">
          Site by Shangxin using
          <a href="http://hexo.io">hexo blog framework</a>
        </div>
      </div>
      <div class="post-date-right">
        
          Mon Nov 20 2017 00:17:16 GMT+0800
        
      </div>
    </div>
    
      

      
        <span id="/2017/11/20/TensorFlow-学习笔记/" class="leancloud-visitors view" data-flag-title>
          <em class="post-meta-item-text">阅读量 </em>
          <i class="leancloud-visitors-count">不知道 &gt;_&lt;</i>
        </span>
      
    
    <!-- 不蒜子网站访问量统计 -->
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
  </div>
</div>


  <!-- scripts list from theme config.yml -->
  
    <script src="/js/acanal.js"></script>
  


</body>
</html>
