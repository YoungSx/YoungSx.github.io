<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Shangxin"><title>TensorFlow 学习笔记 · 不懂鸟语的人</title><meta name="description" content="TensorFlow 学习笔记@(深度学习)
纯粹的学习笔记，写给自己看的，防止遗忘。
定义公式定义的公式只是 Computation Graph，在这执行这代码时计算还没发生，需要调用 run 方法并 feed 数据才真正执行。
流程
定义算法公式，也就是神经网络 forward 时的计算。
定义"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">不懂鸟语的人</a></h3><div class="description"><p>Shangxin 的个人学习笔记。精力原因，也许只为自己方便翻阅。</p></div></div></div><ul class="social-links"><li><a href="https://twitter.com/YangShangxin"><i class="fa fa-twitter"></i></a></li><li><a href="http://github.com/YoungSx"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/fbb.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>TensorFlow 学习笔记</a></h3></div><div class="post-content"><h1 id="TensorFlow-学习笔记"><a href="#TensorFlow-学习笔记" class="headerlink" title="TensorFlow 学习笔记"></a>TensorFlow 学习笔记</h1><p>@(深度学习)</p>
<p>纯粹的学习笔记，写给自己看的，防止遗忘。</p>
<h2 id="定义公式"><a href="#定义公式" class="headerlink" title="定义公式"></a>定义公式</h2><p>定义的公式只是 Computation Graph，在这执行这代码时计算还没发生，需要调用 run 方法并 feed 数据才真正执行。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol>
<li>定义算法公式，也就是神经网络 forward 时的计算。</li>
<li>定义 loss ，选定优化器，并指定优化器优化 loss。</li>
<li>迭代地对数据进行训练。</li>
<li>在测试集或验证集上对准确率进行评测。</li>
</ol>
<p>lambda</p>
<p>dense</p>
<h2 id="tf-nn-relu"><a href="#tf-nn-relu" class="headerlink" title="tf.nn.relu"></a>tf.nn.relu</h2><h2 id="tf-nn-tanh"><a href="#tf-nn-tanh" class="headerlink" title="tf.nn.tanh"></a>tf.nn.tanh</h2><h2 id="tf-nn-moment"><a href="#tf-nn-moment" class="headerlink" title="tf.nn.moment"></a>tf.nn.moment</h2><h2 id="tf-nn-softmax-cross-entropy-with-logits"><a href="#tf-nn-softmax-cross-entropy-with-logits" class="headerlink" title="tf.nn.softmax_cross_entropy_with_logits()"></a>tf.nn.softmax_cross_entropy_with_logits()</h2><p>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))<br>    =&gt;<br>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))</p>
<h2 id="tf-stack"><a href="#tf-stack" class="headerlink" title="tf.stack()"></a>tf.stack()</h2><p>tf.pack() =&gt; tf.stack()<br>tf.unpack() =&gt; tf.unstack()</p>
<h2 id="tf-nn-dropout"><a href="#tf-nn-dropout" class="headerlink" title="tf.nn.dropout()"></a>tf.nn.dropout()</h2><h2 id="tf-truncated-normal"><a href="#tf-truncated-normal" class="headerlink" title="tf.truncated_normal()"></a>tf.truncated_normal()</h2><h2 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a>tf.reshape()</h2><p>重新变换形状</p>
<h2 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean()"></a>tf.reduce_mean()</h2><p>在某一维度上求平均值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reduce_mean(</span><br><span class="line">    input_tensor,</span><br><span class="line">    axis=None,</span><br><span class="line">    keepdims=None,</span><br><span class="line">    name=None,</span><br><span class="line">    reduction_indices=None,</span><br><span class="line">    keep_dims=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable()</span><br></pre></td></tr></table></figure>
<h2 id="tf-name-scope"><a href="#tf-name-scope" class="headerlink" title="tf.name_scope()"></a>tf.name_scope()</h2><p>对 tf.get_variable() 无效</p>
<h3 id="scope-reuse-variables"><a href="#scope-reuse-variables" class="headerlink" title="scope.reuse_variables()"></a>scope.reuse_variables()</h3><p>后面加    tf.get_variable() 可以重复用</p>
<h2 id="tf-equal"><a href="#tf-equal" class="headerlink" title="tf.equal()"></a>tf.equal()</h2><p>判断两个是否相等</p>
<h2 id="tf-cast"><a href="#tf-cast" class="headerlink" title="tf.cast()"></a>tf.cast()</h2><p>映射，参数一映射为参数二的类型</p>
<h2 id="tf-placeholder"><a href="#tf-placeholder" class="headerlink" title="tf.placeholder()"></a>tf.placeholder()</h2><p>占位符<br>input = tf.placeholder(tf.float32)<br>操作 = 函数(input)<br>sess.run(操作, feed_dict = {input: 2})</p>
<p>tf.placeholder(tf.float32, [None, 784])<br>第二个参数代表 tensor 的 shape， 也就是数据的尺寸。<br>None 代表不限条数的输入，784 代表每条输入是一个784 维的向量。</p>
<h2 id="tf-argmax"><a href="#tf-argmax" class="headerlink" title="tf.argmax"></a>tf.argmax</h2><p>返回最大值的索引</p>
<h2 id="tf-train"><a href="#tf-train" class="headerlink" title="tf.train"></a>tf.train</h2><h3 id="tf-train-Saver"><a href="#tf-train-Saver" class="headerlink" title="tf.train.Saver()"></a>tf.train.Saver()</h3><p>保存(save) 恢复(restore) 模型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># save</span><br><span class="line">saver.save(sess, &apos;my-model&apos;, global_step = 0)</span><br><span class="line"># restore</span><br><span class="line">saver.restore(sess, &apos;my-model&apos;)</span><br></pre></td></tr></table></figure></p>
<h2 id="tf-nn-rnn-cell"><a href="#tf-nn-rnn-cell" class="headerlink" title="tf.nn.rnn_cell"></a>tf.nn.rnn_cell</h2><p>tf.nn.rnn_cell =&gt; tf.contrib.rnn</p>
<h3 id="tf-train-GradientDescentOptimizer"><a href="#tf-train-GradientDescentOptimizer" class="headerlink" title="tf.train.GradientDescentOptimizer()"></a>tf.train.GradientDescentOptimizer()</h3><p>梯度下降优化器</p>
<h2 id="tf-summary-FileWriter"><a href="#tf-summary-FileWriter" class="headerlink" title="tf.summary.FileWriter"></a>tf.summary.FileWriter</h2><p>tf.trian.SummaryWriter =&gt; tf.summary.FileWriter<br>Writes Summary protocol buffers to event files.</p>
<h2 id="tf-global-variables-initializer"><a href="#tf-global-variables-initializer" class="headerlink" title="tf.global_variables_initializer()"></a>tf.global_variables_initializer()</h2><p>tf.initialize_all_variables() =&gt; tf.global_variables_initializer()</p>
<h2 id="tf-matmul"><a href="#tf-matmul" class="headerlink" title="tf.matmul()"></a>tf.matmul()</h2><p>两个矩阵相乘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">matmul(</span><br><span class="line">    a,</span><br><span class="line">    b,</span><br><span class="line">    transpose_a=False,</span><br><span class="line">    transpose_b=False,</span><br><span class="line">    adjoint_a=False,</span><br><span class="line">    adjoint_b=False,</span><br><span class="line">    a_is_sparse=False,</span><br><span class="line">    b_is_sparse=False,</span><br><span class="line">    name=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="tf-square"><a href="#tf-square" class="headerlink" title="tf.square()"></a>tf.square()</h2><p>平方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">square(</span><br><span class="line">    x,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-11-20</span><i class="fa fa-tag"></i><a class="tag" href="/tags/深度学习/" title="深度学习">深度学习 </a><a class="tag" href="/tags/TensorFlow/" title="TensorFlow">TensorFlow </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2017/11/20/TensorFlow-学习笔记/,不懂鸟语的人,TensorFlow 学习笔记,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/01/21/曲折的求职（ShiXi）经历/" title="曲折的求职（ShiXi）经历">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2017/10/12/Laravel-安装笔记/" title="Laravel 安装笔记">下一篇</a></li></ul></div><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@v1.1.7/dist/Valine.min.js?v=undefined"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'b47PMHdzebB0ozGGdW68aQAN-gzGzoHsz',
  app_key:'pnCuygqUh5uDjQt8wNEKSd8K',
  placeholder:'Just go go',
  path: window.location.pathname,
  avatar:'mm'
})</script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>